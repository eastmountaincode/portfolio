{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "howToGetReviewDataFromYelp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A6qwi69zDcqp",
        "byrY7SeiMe7r",
        "0L6lBaAdMAwR",
        "bUb-8WlyRvEH",
        "8Rtbih9oSudh"
      ],
      "authorship_tag": "ABX9TyNMjww+hGUQ9R5e7l0mbwpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eastmountaincode/DSC/blob/main/howToGetReviewDataFromYelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDoxqFomAsBu"
      },
      "source": [
        "The following is a documentation of the process of getting review data from Yelp using a combination of the Yelp Fusion API and APIFY, a web scraping service (https://apify.com/). We use the Yelp Fusion API to get a list of businesses, and then we use APIFY to scrape the reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGP9uVW4BgWX"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7zbUjEjAl4t"
      },
      "source": [
        "#Install required packackge\n",
        "!pip install yelpapi\n",
        "\n",
        "#Import required libraries\n",
        "import pandas as pd\n",
        "from yelpapi import YelpAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBcqq2h-Bejt"
      },
      "source": [
        "#Mount google drive if needed (this code was created with Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njr4j6s0CEjC"
      },
      "source": [
        "You will need an API key for the Yelp Fusion API. You can learn how to obtain an API key at this link: https://www.yelp.com/developers/documentation/v3/authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR_8TWx7B2H8"
      },
      "source": [
        "yelp_api = YelpAPI(\"your api key goes here!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6qwi69zDcqp"
      },
      "source": [
        "## Option 1/2: If getting data from just one location..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3FMe_jJDmbF"
      },
      "source": [
        "#Create a blank dataframe\n",
        "businessdf = pd.DataFrame(columns=[\"BusinessName\", \"ID\", \"City\", \"State\", \"TotalRating\", \"URL\", \"bizType\" ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_paL6EXfD-vO"
      },
      "source": [
        "Yelp Fusion's list of categories is pleasantly comprehensive. Here's the link: https://www.yelp.com/developers/documentation/v3/all_category_list. Find the correct category name for the type of business you're looking for. In this case, let's search for ice cream shops, which has a category name of \"icecream\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVW0CT7eDupT"
      },
      "source": [
        "#Category name and location get inserted as parameter in this step\n",
        "#Note that 50 is that maximum number of businesses we can get back from a single search\n",
        "#A workaround for this could be to search in several nearby cities and then remove the duplicates\n",
        "search_results = yelp_api.search_query(categories='icecream', location=\"Cincinnati\", limit=50, radius=40000)\n",
        "for businessi in range(len(search_results['businesses'])):\n",
        "  #Just to be safe CHECK IF CATEGORY ALIAS MATCHES THE CATEGORY WE WANT\n",
        "  if search_results['businesses'][0]['categories'][0]['alias'] == \"icecream\":\n",
        "    if search_results['businesses'][businessi]['location']['state'] == \"OH\":\n",
        "      #GET THE INFO\n",
        "      businessname = search_results['businesses'][businessi]['alias']\n",
        "      ID = search_results['businesses'][businessi]['id']\n",
        "      actualCity = search_results['businesses'][businessi]['location']['city']\n",
        "      state = search_results['businesses'][businessi]['location']['state']\n",
        "      rating = search_results['businesses'][businessi]['rating']\n",
        "      url = search_results['businesses'][businessi]['url']\n",
        "      bizType = \"iceCream\"\n",
        "      \n",
        "      new_row = {'BusinessName': businessname, 'ID': ID, 'City': actualCity, 'State': state, \"TotalRating\": rating, \"URL\": url, \"bizType\": bizType}\n",
        "      businessdf = businessdf.append(new_row, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYAyhdjaGLNs"
      },
      "source": [
        "display(businessdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qu2zosHHVnb"
      },
      "source": [
        "The following code gives us a bunch of Yelp URLs that APIFY can read. Copy and paste ALL of this (If you're on Google Colab, right click and go to \"view output fullscreen\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VIGx1CHA60"
      },
      "source": [
        "for i in range(len(businessdf)):\n",
        "  print('\"{}\",'.format(businessdf.loc[i, \"URL\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8G7EivJFru"
      },
      "source": [
        "Now go to APIFY. Create a new task. Search for Yelp Scraper. Go to the Input tab. Remove search terms. Remove locations. Set search results limit to 99999999. In direct Yelp page URLs, type in some random characters, it doesn't matter what. Ignore the error message. Set maximum reviews to 99999999. Set max images to 0. Now switch from editor view to JSON view at the top left. In the list called direct URLs, paste in the the list of URLs that you got from this code. Remove the very last comma. You should now be able to switch back over to editor view if everything worked correctly. Run the scraper. Download the JSON dataset from APIFY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byrY7SeiMe7r"
      },
      "source": [
        "## Option 2/2: If getting data from multiple locations..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa6dRoGVUj0W"
      },
      "source": [
        "Import a list of locations you want to search. In this case, I used a CSV file containting every city in Ohio ordered by population. I got this list from this link: https://www.ohio-demographics.com/cities_by_population (it required a bit of cleaning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUQIVCdUeW9"
      },
      "source": [
        "citydf = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Yelp/OhioPopulationByCity.csv\", index_col= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhG2CE0fU8MD"
      },
      "source": [
        "citylist = []\n",
        "\n",
        "for i in range(len(citydf)):\n",
        "  city = citydf.loc[i, \"City\"]\n",
        "  fullcity = \"{}, OH\".format(city)\n",
        "  citylist.append(fullcity)\n",
        "\n",
        "#...ALSO APPEND \" ,OH\" TO THE END OF EVERY CITY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvJEDiJYVAKw"
      },
      "source": [
        "#Let's just do the first 10 most populous cities for this example...\n",
        "citylist = citylist[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LnSTzy9VK1i",
        "outputId": "b7f17185-3ffa-4cfb-fd85-44fdd36b2931"
      },
      "source": [
        "citylist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Columbus, OH',\n",
              " 'Cleveland, OH',\n",
              " 'Cincinnati, OH',\n",
              " 'Toledo, OH',\n",
              " 'Akron, OH',\n",
              " 'Dayton, OH',\n",
              " 'Parma, OH',\n",
              " 'Canton, OH',\n",
              " 'Youngstown, OH',\n",
              " 'Lorain, OH']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-XaF1yDUbIq"
      },
      "source": [
        "counter = 0\n",
        "#FOR EVERY CITY, SEARCH FOR URGENT CARE\n",
        "for cityname in citylist:\n",
        "  search_results = yelp_api.search_query(categories='icecream', location=cityname, limit=50, radius=40000)\n",
        "  #CHECK IF CATEGORY ALIAS MATCHES THE CATEGORY WE WANT\n",
        "  for businessi in range(len(search_results['businesses'])):\n",
        "    if search_results['businesses'][0]['categories'][0]['alias'] == \"icecream\":\n",
        "      #This line causes the code to only includes businesses located in Ohio\n",
        "      if search_results['businesses'][businessi]['location']['state'] == \"OH\":\n",
        "        #GET THE INFO\n",
        "        businessname = search_results['businesses'][businessi]['alias']\n",
        "        ID = search_results['businesses'][businessi]['id']\n",
        "        actualCity = search_results['businesses'][businessi]['location']['city']\n",
        "        state = search_results['businesses'][businessi]['location']['state']\n",
        "        rating = search_results['businesses'][businessi]['rating']\n",
        "        url = search_results['businesses'][businessi]['url']\n",
        "        bizType = \"iceCream\"\n",
        "        \n",
        "        new_row = {'BusinessName': businessname, 'ID': ID, 'City': actualCity, 'State': state, \"TotalRating\": rating, \"URL\": url, \"bizType\": bizType}\n",
        "        businessdf = businessdf.append(new_row, ignore_index=True)\n",
        "  counter += 1\n",
        "  print(round(((counter / len(citylist)) * 100), 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AanAZKhVmwC"
      },
      "source": [
        "#Because we did multiple searches, we need to make sure we don't have any duplicates...\n",
        "businessdf = pd.DataFrame.drop_duplicates(businessdf)\n",
        "businessdf.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vXqpokJVz4P"
      },
      "source": [
        "display(businessdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W13HjHBWPli"
      },
      "source": [
        "The following code gives us a bunch of Yelp URLs that APIFY can read. Copy and paste ALL of this (If you're on Google Colab, right click and go to \"view output fullscreen\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "902yXQGRWSlJ"
      },
      "source": [
        "for i in range(len(businessdf)):\n",
        "  print('\"{}\",'.format(businessdf.loc[i, \"URL\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmVYT-fMWVEN"
      },
      "source": [
        "Now go to APIFY. Create a new task. Search for Yelp Scraper. Go to the Input tab. Remove search terms. Remove locations. Set search results limit to 99999999. In direct Yelp page URLs, type in some random characters, it doesn't matter what. Ignore the error message. Set maximum reviews to 99999999. Set max images to 0. Now switch from editor view to JSON view at the top left. In the list called direct URLs, paste in the the list of URLs that you got from this code. Remove the very last comma. You should now be able to switch back over to editor view if everything worked correctly. Run the scraper. Download the JSON dataset from APIFY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L6lBaAdMAwR"
      },
      "source": [
        "## Working with the data from APIFY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHk82zp5MEy9"
      },
      "source": [
        "For the next step, I'll be using the data I got from doing the steps under \"If getting data from just one location...\". I have JSON with 46 businesses and lots of metadata. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDZSlaqALeX1"
      },
      "source": [
        "#Import the JSON dataset from APIFY\n",
        "\n",
        "APIFYdf = pd.read_json(\"/content/drive/My Drive/Colab Notebooks/Yelp/YelpTutorialAPIFY.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meWJEEFKRVFR"
      },
      "source": [
        "display(APIFYdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUb-8WlyRvEH"
      },
      "source": [
        "## Option 1/2: If you want to make a dataframe where each row is a separate review..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TCZxZn6Rp4y"
      },
      "source": [
        "#REVIEW SCALE\n",
        "\n",
        "reviewScaleDF = pd.DataFrame(columns=[\"businessTitle\", \"directURL\", \"businessID\", \"phoneNum\", \"address\", \"city\", \"state\", \"businessRating\", \"reviewDate\", \"reviewText\", \"reviewRating\", \"bizType\", \"dataSource\"])\n",
        "for business in range(len(APIFYdf)):\n",
        "  #Let's say we only want businesses that are explicitly ice cream stores... we can add this line:\n",
        "  if APIFYdf.loc[business, \"cuisine\"] == \"Ice Cream & Frozen Yogurt\":\n",
        "    for review in range(len(APIFYdf.loc[business, 'reviews'])):\n",
        "\n",
        "      businessTitle = APIFYdf.loc[business, 'name']\n",
        "      directURL = APIFYdf.loc[business, 'directUrl']\n",
        "      businessID = APIFYdf.loc[business, 'bizId']\n",
        "      phoneNum = APIFYdf.loc[business, 'phone']\n",
        "      addressaggregate = \"{0}, {1}, {2}, {3}\".format((APIFYdf.loc[business, \"address\"]['addressLine1']), (APIFYdf.loc[business, \"address\"]['city']), (APIFYdf.loc[business, \"address\"]['regionCode']), (APIFYdf.loc[business, \"address\"]['postalCode']))\n",
        "      city = APIFYdf.loc[business, 'address']['city']\n",
        "      state = APIFYdf.loc[business, 'address']['regionCode']\n",
        "\n",
        "      overallRating = APIFYdf.loc[business, 'aggregatedRating']\n",
        "\n",
        "      theDate = APIFYdf.loc[business, 'reviews'][review]['date'][0:10]\n",
        "\n",
        "      reviewText = APIFYdf.loc[business, 'reviews'][review]['text']\n",
        "      reviewRating = APIFYdf.loc[business, 'reviews'][review]['rating']\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      new_row = {'businessTitle': businessTitle,\n",
        "                'directURL': directURL,\n",
        "                'businessID': businessID,\n",
        "                'phoneNum': phoneNum,\n",
        "                'address': addressaggregate,\n",
        "                'city': city,\n",
        "                'state': state,\n",
        "                'businessRating': overallRating,\n",
        "                'reviewDate': theDate,\n",
        "                \"reviewText\": reviewText,\n",
        "                \"reviewRating\": reviewRating,\n",
        "                \"bizType\": \"iceCream\",\n",
        "                \"dataSource\": \"Yelp\"}\n",
        "      reviewScaleDF = reviewScaleDF.append(new_row, ignore_index=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GejQPyyZSdkx"
      },
      "source": [
        "display(reviewScaleDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52F_J0EySy7y"
      },
      "source": [
        "#Download the file as a CSV\n",
        "from google.colab import files\n",
        "reviewScaleDF.to_csv(\"reviewScaleIceCreamYelp.csv\")\n",
        "files.download(\"reviewScaleIceCreamYelp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rtbih9oSudh"
      },
      "source": [
        "## Option 2/2: If you want to make a dataframe where each row is one business, and the review text is stored in a column with one big review, a concatenation of ALL that reviews for that business..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsq15WjWTIvR"
      },
      "source": [
        "institutionalScaleDF = pd.DataFrame(columns=[\"businessTitle\", \"directURL\", \"businessID\", \"phoneNum\", \"address\", \"city\", \"state\", \"businessRating\", \"bigReview\", \"numberOfReviews\", \"bizType\", \"dataSource\"])\n",
        "\n",
        "for business in range(len(APIFYdf)):\n",
        "  #Let's say we only want businesses that are explicitly ice cream stores... we can add this line:\n",
        "  if APIFYdf.loc[business, \"cuisine\"] == \"Ice Cream & Frozen Yogurt\":\n",
        "    businessTitle = APIFYdf.loc[business, 'name']\n",
        "    directURL = APIFYdf.loc[business, 'directUrl']\n",
        "    businessID = APIFYdf.loc[business, 'bizId']\n",
        "    phoneNum = APIFYdf.loc[business, 'phone']\n",
        "    addressaggregate = \"{0}, {1}, {2}, {3}\".format((APIFYdf.loc[business, \"address\"]['addressLine1']), (APIFYdf.loc[business, \"address\"]['city']), (APIFYdf.loc[business, \"address\"]['regionCode']), (APIFYdf.loc[business, \"address\"]['postalCode']))\n",
        "    city = APIFYdf.loc[business, 'address']['city']\n",
        "    state = APIFYdf.loc[business, 'address']['regionCode']\n",
        "\n",
        "    overallRating = APIFYdf.loc[business, 'aggregatedRating']\n",
        "\n",
        "    bigText = \"\"\n",
        "    numOfReviews = 0\n",
        "    #For each review...\n",
        "    for review in range(len(APIFYdf.loc[business, 'reviews'])):\n",
        "      #If the review has text, meaning it's not just a rating based on number of stars...\n",
        "      if APIFYdf.loc[business, 'reviews'][review]['text']:\n",
        "        reviewText = APIFYdf.loc[business, 'reviews'][review]['text']\n",
        "        #...append the review to this string called big text, and separate individual reviews with a newline, 10 tildes, and another newline.\n",
        "        bigText = bigText + reviewText\n",
        "        bigText = bigText + \"\\n\" + \"~~~~~~~~~~\" + \"\\n\"\n",
        "        numOfReviews += 1\n",
        "\n",
        "    \n",
        "    if bigText:\n",
        "    \n",
        "      new_row = {'businessTitle': businessTitle,\n",
        "                'directURL': directURL,\n",
        "                'businessID': businessID,\n",
        "                'phoneNum': phoneNum,\n",
        "                'address': addressaggregate,\n",
        "                'city': city,\n",
        "                'state': state,\n",
        "                'businessRating': overallRating,\n",
        "                'bigReview': bigText,\n",
        "                'numberOfReviews': numOfReviews,\n",
        "                'bizType': \"urgentCare\",\n",
        "                \"dataSource\": \"Yelp\"}\n",
        "      institutionalScaleDF = institutionalScaleDF.append(new_row, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9zvAy4tUMsm"
      },
      "source": [
        "display(institutionalScaleDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH4pP9sRTIt3"
      },
      "source": [
        "#An example of what one big concatenated review looks like\n",
        "display(institutionalScaleDF.loc[3, \"bigReview\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n6By6ntTbqE"
      },
      "source": [
        "#Download the file as a CSV\n",
        "from google.colab import files\n",
        "institutionalScaleDF.to_csv(\"institutionalScaleIceCreamYelp.csv\")\n",
        "files.download(\"institutionalScaleIceCreamYelp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}