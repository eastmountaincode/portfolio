{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "howToGetReviewDataFromGoogleMaps.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hTUtYWVm6jto",
        "W71MJXb08NBR"
      ],
      "authorship_tag": "ABX9TyOWhSsLRlNVen0tBktmxSAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eastmountaincode/DSC/blob/main/howToGetReviewDataFromGoogleMaps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNw86pd4hRkM"
      },
      "source": [
        "The following is a documentation of the process of getting review data from Google Maps using a combination of the Google Places API and APIFY, a web scraping service (https://apify.com/). We use the Google Places API to get a list of businesses, and then we use APIFY to scrape the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ZJ4V1RZCw1"
      },
      "source": [
        "#Importing libraries\n",
        "import pandas as pd\n",
        "import requests, json\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZydgBgzNhq2e"
      },
      "source": [
        "You will need an API key for the Google Places API. This can be obtained by making a Google Cloud account. You can learn how to obtain and API key at this link: https://developers.google.com/maps/documentation/places/web-service/get-api-key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvykKFVnhoiu"
      },
      "source": [
        "api_key = 'api key goes here'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSoAKppbik77"
      },
      "source": [
        "#Our base URL that we will attach parameters to\n",
        "url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95sD5eHei2Qz"
      },
      "source": [
        "## If getting data from just one location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSL25KQTjwWp"
      },
      "source": [
        "# This is the text string on which to search. This should be altered depending on what you are looking for. \n",
        "# For example, you might set query as \"Honky Tonk in Nashville, TN\" or \"Coffee shop in San Francisco\".\n",
        "\n",
        "query = \"Urgent Care in Cincinnati\"\n",
        "  \n",
        "#The query and API key are attached to the base URL\n",
        "r = requests.get(url + 'query=' + query +\n",
        "                        '&key=' + api_key)\n",
        "  \n",
        "#we convert the response from requestions into a json object\n",
        "currentJSON = r.json()\n",
        "\n",
        "\n",
        "#This is the dataframe where we'll keep all the info we get from the json(s). This initializes an empty dataframe with some defined columns.\n",
        "holdingDF = pd.DataFrame(columns=[\"bizName\", \"placeID\", \"address\", \"placeTypes\", \"numOfRatings\"])\n",
        "\n",
        "#each json we get from our get request will have 50 businesses. If there are more businesses, there will be a 'next_page_token'.\n",
        "#we want the following while loop to run at least once regardless of what we get in our json, so we set isToken to True.\n",
        "isToken = True\n",
        "\n",
        "while isToken:\n",
        "  for business in range(len(currentJSON[\"results\"])):\n",
        "    if 'user_ratings_total' in currentJSON[\"results\"][business]:\n",
        "      bizName = currentJSON[\"results\"][business]['name']\n",
        "      placeID = currentJSON[\"results\"][business]['place_id']\n",
        "      address = currentJSON[\"results\"][business]['formatted_address']\n",
        "\n",
        "      allTypes = \"\"\n",
        "      for eachType in currentJSON[\"results\"][business]['types']:\n",
        "        allTypes = allTypes + \", \" + eachType\n",
        "      allTypes = allTypes[1:]\n",
        "      \n",
        "      numOfRatings = currentJSON[\"results\"][business]['user_ratings_total']\n",
        "\n",
        "      new_row = {'bizName': bizName,\n",
        "                'placeID': placeID,\n",
        "                'address': address,\n",
        "                'placeTypes': allTypes,\n",
        "                'numOfRatings': numOfRatings}\n",
        "      holdingDF = holdingDF.append(new_row, ignore_index=True)\n",
        "\n",
        "  time.sleep(1.5)\n",
        "  #The while loop checks if there is a next_page_token after the loop is complete, but we need this here to check if the FIRST page has one\n",
        "  #If it does, go ahead and load the next JSON. Do display(currentJSON) if you want to get a better idea of how this works.\n",
        "  if 'next_page_token' in currentJSON:\n",
        "    r = requests.get(url + '&key=' + api_key + '&pagetoken=' + currentJSON['next_page_token'])\n",
        "    \n",
        "  currentJSON = r.json()\n",
        "  if 'next_page_token' in currentJSON:\n",
        "    isToken = True\n",
        "  else:\n",
        "    isToken = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVX7kj1AnW0K"
      },
      "source": [
        "display(holdingDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfD0MdD-i5-c"
      },
      "source": [
        "## If getting data from many locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcxFsaAFpPGJ"
      },
      "source": [
        "Maybe we don't want to perform just one search, maybe we want to perform several searches to get results from many different places. For example, what if we wanted to do search in every city in Ohio? This code can help us do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ByGNqppuDW"
      },
      "source": [
        "For this code, I used a CSV file containting every city in Ohio ordered by population. I got this list from this link: https://www.ohio-demographics.com/cities_by_population (it required a bit of cleaning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENvU86CDpK1n",
        "outputId": "adf46103-dd84-4133-8175-4d9e697e5a08"
      },
      "source": [
        "#Importing location data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cityDF = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ERURproject/Yelp/OhioPopulationByCity.csv\", index_col= 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il1EHz9fqX5X"
      },
      "source": [
        "holdingDF = pd.DataFrame(columns=[\"bizName\", \"placeID\", \"address\", \"placeTypes\", \"numOfRatings\"])\n",
        "counter = 0\n",
        "\n",
        "#I limited this search to the first 10 most populated cities in Ohio, hence the range(10).\n",
        "for city in range(10):\n",
        "\n",
        "  #The city name gets passed into the query based on the iteration index\n",
        "  query = \"Urgent Care in {}, Ohio\".format(cityDF.loc[city, 'City'])\n",
        "\n",
        "  r = requests.get(url + 'query=' + query +\n",
        "                          '&key=' + api_key)\n",
        "  currentJSON = r.json()\n",
        "  isToken = True\n",
        "  while isToken:\n",
        "    for business in range(len(currentJSON[\"results\"])):\n",
        "      if 'user_ratings_total' in currentJSON[\"results\"][business]:\n",
        "        bizName = currentJSON[\"results\"][business]['name']\n",
        "        placeID = currentJSON[\"results\"][business]['place_id']\n",
        "        address = currentJSON[\"results\"][business]['formatted_address']\n",
        "\n",
        "        allTypes = \"\"\n",
        "        for eachType in currentJSON[\"results\"][business]['types']:\n",
        "          allTypes = allTypes + \", \" + eachType\n",
        "        allTypes = allTypes[1:]\n",
        "        \n",
        "        numOfRatings = currentJSON[\"results\"][business]['user_ratings_total']\n",
        "\n",
        "        new_row = {'bizName': bizName,\n",
        "                  'placeID': placeID,\n",
        "                  'address': address,\n",
        "                  'placeTypes': allTypes,\n",
        "                  'numOfRatings': numOfRatings}\n",
        "        holdingDF = holdingDF.append(new_row, ignore_index=True)\n",
        "\n",
        "    \n",
        "    time.sleep(1.5)\n",
        "    if 'next_page_token' in currentJSON:\n",
        "      r = requests.get(url + '&key=' + api_key + '&pagetoken=' + currentJSON['next_page_token'])\n",
        "      \n",
        "    # json method of response object convert\n",
        "    #  json format data into python format data\n",
        "    currentJSON = r.json()\n",
        "    if 'next_page_token' in currentJSON:\n",
        "      isToken = True\n",
        "    else:\n",
        "      isToken = False\n",
        "  counter += 1\n",
        "  print(str(round((counter/10)*100, 1)) + \" percent complete\")\n",
        "\n",
        "#Since we're iterating over many cities, some of our search results may overlap. It's important to remove duplicates.\n",
        "holdingDF = pd.DataFrame.drop_duplicates(holdingDF)\n",
        "holdingDF.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzBFT-xQtmfW"
      },
      "source": [
        "display(holdingDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTUtYWVm6jto"
      },
      "source": [
        "## Now that we have a dataframe full of businesses from the Google Places API, the next step is to create a list of URLs we can feed to APIFY."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrXLSkRX7fiJ"
      },
      "source": [
        "#Create a new empty dataframe\n",
        "businessDFurlsDF = pd.DataFrame(columns=[\"name\", \"validURL\", \"placeID\", \"address\", \"city\", \"state\", \"dataSource\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqft2XEf7iVK"
      },
      "source": [
        "#For the placeID of every business...\n",
        "for placeIDindex in range(len(holdingDF)):\n",
        "  \n",
        "  url = \"https://maps.googleapis.com/maps/api/place/details/json?\"\n",
        "  placeIDiter = holdingDF.loc[placeIDindex, 'placeID']  \n",
        "\n",
        "  #Notice that we're now feeding requests a 'place_id=' parameter now\n",
        "  r = requests.get(url + 'place_id=' + placeIDiter +\n",
        "                          '&fields=' + \"name,rating,url,formatted_address\" + '&key=' + api_key)\n",
        "  currentJSON = r.json()\n",
        "\n",
        "  bizName = currentJSON['result']['name']\n",
        "\n",
        "  #This is the important part; the url in the json response for the business gotten by the placeID\n",
        "  #The url contains a 'CID number'. When we append this CID number to the URL form below\n",
        "  #It takes the form of a URL that APIFY can read. \n",
        "  placeIDtoSave = currentJSON['result']['url']\n",
        "  theGoldenCID = placeIDtoSave.split('cid=')[1]\n",
        "  validURL = 'https://www.google.com/maps/place/?cid=' + theGoldenCID\n",
        "\n",
        "  address = currentJSON['result']['formatted_address']\n",
        "\n",
        "  city = address.split(',')[1].strip()\n",
        "  state = address.split(',')[2].strip()[0:2]\n",
        "\n",
        "  #We've gotten some extra information like address ad city, but the important colimn is 'validURL'. \n",
        "  #This is what we'll use in the next step\n",
        "  new_row = {'name': bizName,\n",
        "            'validURL': validURL,\n",
        "            'placeID': placeIDiter,\n",
        "            'address': address,\n",
        "            'city': city,\n",
        "            'state': state,\n",
        "              'dataSource': \"GoogleMaps\"}\n",
        "  businessDFurlsDF = businessDFurlsDF.append(new_row, ignore_index=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIc6X6tk6geS"
      },
      "source": [
        "validPlaceIDlist = []\n",
        "\n",
        "for validURL in range(len(businessDFurlsDF)):\n",
        "  validPlaceIDlist.append(businessDFurlsDF.loc[validURL, 'validURL'])\n",
        "\n",
        "#remove duplicates\n",
        "newlist = list(set(validPlaceIDlist))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MpfP_a88GHE"
      },
      "source": [
        "display(newlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W71MJXb08NBR"
      },
      "source": [
        "## Now download the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUsEWmrF8Qdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "88c27b27-69e7-46ad-cb53-dd20af9376d3"
      },
      "source": [
        "from google.colab import files\n",
        "df = pd.DataFrame(newlist)\n",
        "df.to_csv('placeIDlistforAPIFY.csv', index=False)\n",
        "files.download('placeIDlistforAPIFY.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8bf571ba-432b-4059-acee-164308fc1b32\", \"placeIDlistforAPIFY.csv\", 20347)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPA_O2R27-AW"
      },
      "source": [
        "## Now we go to APIFY. Create a new \"task\" and choose the Google Maps Scraper. Plug in the CSV list that we made in the last step to \"Start URLs\" (choose upload text file). Remove search terms. Set max crawled places to 0. Under output configuration set max reviews to 99999. Set max images to 0. Uncheck include popular times. Sort reviews by \"Newest\". Run the scraper. APIFY will give you a JSON file. Download it and bring it into this code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct3ts5bJ-ELi"
      },
      "source": [
        "Using the previous code, I ran a search for \"Urgent Care in Cincinnati\", received 40 businesses, and put the CSV file in APIFY. I got back a JSON, which I'm importing into the code now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ4IudLm92zj",
        "outputId": "a4a64881-e1a9-4158-8fc4-7011d572fe33"
      },
      "source": [
        "#Mount the drive in case we haven't already.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataFromAPIFYDF = pd.read_json(\"/content/drive/My Drive/Colab Notebooks/Google/GoogleTutorialData.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaWrzQX1-30-"
      },
      "source": [
        "## If you want to make a dataframe where each row is a separate review..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkbaE7T_CPQ"
      },
      "source": [
        "#REVIEW SCALE\n",
        "\n",
        "\n",
        "reviewScaleDF = pd.DataFrame(columns=[\"businessTitle\", \"googleURL\", \"CIDnum\", \"phoneNum\", \"address\", \"city\", \"state\", \"businessRating\", \"reviewDate\", \"reviewText\", \"reviewRating\", \"bizType\", \"dataSource\"])\n",
        "counter = 0\n",
        "for business in range(len(dataFromAPIFYDF)):\n",
        "  #Our search will have given us businesses that are not urgent care centers, and since Cincinnati is very close to Kentucky, we may get some results from KY\n",
        "  #This next step filters results to only include businesses that are in Ohio and that have the categoryName 'Urgent care center'\n",
        "  if dataFromAPIFYDF.loc[business, 'categoryName'] == 'Urgent care center' and 'OH' in dataFromAPIFYDF.loc[business, 'address']:\n",
        "    for review in range(len(dataFromAPIFYDF.loc[business, 'reviews'])):\n",
        "\n",
        "      businessTitle = dataFromAPIFYDF.loc[business, 'title']\n",
        "      directURL = dataFromAPIFYDF.loc[business, 'placeId']\n",
        "      placeIDtoSave = dataFromAPIFYDF.loc[business, 'placeId']\n",
        "\n",
        "      theGoldenCID = placeIDtoSave.split('cid=')[1]\n",
        "\n",
        "      phoneNum = dataFromAPIFYDF.loc[business, 'phone']\n",
        "      address = dataFromAPIFYDF.loc[business, 'address']\n",
        "      city = address.split(',')[1].strip()\n",
        "      state = address.split(',')[2].strip()[0:2]\n",
        "\n",
        "      overallRating = dataFromAPIFYDF.loc[business, 'totalScore']\n",
        "      theDate = dataFromAPIFYDF.loc[business, 'reviews'][review]['publishedAtDate'][0:10]\n",
        "\n",
        "      reviewText = dataFromAPIFYDF.loc[business, 'reviews'][review]['text']\n",
        "      reviewRating = dataFromAPIFYDF.loc[business, 'reviews'][review]['stars']\n",
        "\n",
        "\n",
        "      if reviewText:\n",
        "        new_row = {'businessTitle': businessTitle,\n",
        "                  'googleURL': directURL,\n",
        "                  'CIDnum': theGoldenCID,\n",
        "                  'phoneNum': phoneNum,\n",
        "                  'address': address,\n",
        "                  'city': city,\n",
        "                  'state': state,\n",
        "                  'businessRating': overallRating,\n",
        "                  'reviewDate': theDate,\n",
        "                  \"reviewText\": reviewText,\n",
        "                  \"reviewRating\": reviewRating,\n",
        "                  \"bizType\": \"urgentCare\",\n",
        "                  \"dataSource\": \"Google\"}\n",
        "        reviewScaleDF = reviewScaleDF.append(new_row, ignore_index=True)\n",
        "  counter += 1\n",
        "  number = (counter/len(dataFromAPIFYDF)*100)\n",
        "  print(round(number, 2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kVgcaJ0_IsC"
      },
      "source": [
        "display(reviewScaleDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ls4b3psL_OGi",
        "outputId": "fe6d308b-bd61-4986-c5c7-776965800d11"
      },
      "source": [
        "from google.colab import files\n",
        "reviewScaleDF.to_csv(\"reviewScaleUrgentCareGoogle.csv\")\n",
        "files.download(\"reviewScaleUrgentCareGoogle.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3cc81923-d1c4-4a53-96c6-d114ad0fe3ee\", \"reviewScaleUrgentCareGoogle.csv\", 1331268)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiT3vuBM_Ys_"
      },
      "source": [
        "## If you want to make a dataframe where each row is one business, and the review text is stored in a column with one big review, a concatenation of ALL that reviews for that business..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeVprSTP_r21"
      },
      "source": [
        "#INSTITUTION SCALE\n",
        "\n",
        "\n",
        "institutionalScaleDF = pd.DataFrame(columns=[\"businessTitle\", \"googleURL\", \"CIDnum\", \"phoneNum\", \"address\", \"city\", \"state\", \"businessRating\", \"bigText\", \"numberOfReviews\", \"bizType\", \"dataSource\"])\n",
        "counter = 0\n",
        "for business in range(len(dataFromAPIFYDF)):\n",
        "  #Our search will have given us businesses that are not urgent care centers, and since Cincinnati is very close to Kentucky, we may get some results from KY\n",
        "  #This next step filters results to only include businesses that are in Ohio and that have the categoryName 'Urgent care center'\n",
        "  if dataFromAPIFYDF.loc[business, 'categoryName'] == 'Urgent care center' and 'OH' in dataFromAPIFYDF.loc[business, 'address']:\n",
        "\n",
        "    businessTitle = dataFromAPIFYDF.loc[business, 'title']\n",
        "    directURL = dataFromAPIFYDF.loc[business, 'placeId']\n",
        "    placeIDtoSave = dataFromAPIFYDF.loc[business, 'placeId']\n",
        "\n",
        "    theGoldenCID = placeIDtoSave.split('cid=')[1]\n",
        "\n",
        "    phoneNum = dataFromAPIFYDF.loc[business, 'phone']\n",
        "    address = dataFromAPIFYDF.loc[business, 'address']\n",
        "    city = address.split(',')[1].strip()\n",
        "    state = address.split(',')[2].strip()[0:2]\n",
        "\n",
        "    overallRating = dataFromAPIFYDF.loc[business, 'totalScore']\n",
        "\n",
        "    bigText = \"\"\n",
        "    numOfReviews = 0\n",
        "    #For each review...\n",
        "    for review in range(len(dataFromAPIFYDF.loc[business, 'reviews'])):\n",
        "      #If the review has text, meaning it's not just a rating based on number of stars...\n",
        "      if dataFromAPIFYDF.loc[business, 'reviews'][review]['text']:\n",
        "        reviewText = dataFromAPIFYDF.loc[business, 'reviews'][review]['text']\n",
        "        #...append the review to this string called big text, and separate individual reviews with a newline, 10 tildes, and another newline.\n",
        "        bigText = bigText + reviewText\n",
        "        bigText = bigText + \"\\n\" + \"~~~~~~~~~~\" + \"\\n\"\n",
        "        numOfReviews += 1\n",
        "        \n",
        "\n",
        "\n",
        "    #Make sure the business had a least ONE review with text in it...\n",
        "    if bigText:\n",
        "      new_row = {'businessTitle': businessTitle,\n",
        "                'googleURL': directURL,\n",
        "                'CIDnum': theGoldenCID,\n",
        "                'phoneNum': phoneNum,\n",
        "                'address': address,\n",
        "                'city': city,\n",
        "                'state': state,\n",
        "                'businessRating': overallRating,\n",
        "                \"bigText\": bigText,\n",
        "                \"numberOfReviews\": numOfReviews,\n",
        "                \"bizType\": \"urgentCare\",\n",
        "                \"dataSource\": \"Google\"}\n",
        "      institutionalScaleDF = institutionalScaleDF.append(new_row, ignore_index=True)\n",
        "  counter += 1\n",
        "  number = (counter/len(dataFromAPIFYDF)*100)\n",
        "  print(round(number, 2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybywe7Ds_wP2"
      },
      "source": [
        "display(institutionalScaleDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z5_8NHQT_zig",
        "outputId": "c1c217e8-1c6c-4d21-b058-79d4a2f3d439"
      },
      "source": [
        "from google.colab import files\n",
        "institutionalScaleDF.to_csv(\"institutionalScaleUrgentCareGoogle.csv\")\n",
        "files.download(\"institutionalScaleUrgentCareGoogle.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4d2a1253-7ee7-4fe1-b130-cd407ff33fe4\", \"institutionalScaleUrgentCareGoogle.csv\", 777931)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}